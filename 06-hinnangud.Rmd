# Statistilised hinnangud
## Punkthinnangud

Mõistmaks punktihinnanguid, on oluline eristada valimi karakteristikuid üldkogumi vastavatest parameetritest. Punktihinnang on valimi andmetel arvutatud üksik väärtus, mida kasutatakse üldkogumi parameetri hindamiseks. Alljärgnevalt on kirjeldatud küsitud punktihinnangud, tuginedes antud allikatele.

### Valimi maht

Valimi maht on valimisse kuuluvate elementide arv. Valimi mahu tähis on $n$. Valimi maht on oluline, kuna see mõjutab hinnangute täpsust. Suurema valimi korral on hinnangud üldjuhul täpsemad ja usaldusväärsemad kui väikese valimi korral. Valimi suuruse määramiseks on olemas valemid, mis arvestavad soovitavat täpsust ja usaldusnivood.

### Aritmeetiline keskmine

Aritmeetiline keskmine on valimi väärtuste summa jagatud valimi mahuga. See on mahukeskmine, mis tähendab, et selle väärtus sõltub igast üksikust valimi väärtusest. Aritmeetiline keskmine on efektiivne hinnang üldkogumi keskväärtusele, kuna see on nihketa ja väikseima hajuvusega hinnang. Aritmeetilise keskmise arvutamise valem on järgmine:


\[\bar{x} = \frac{1}{n} \sum_{i=1}^{n} x_i\]


kus $x_i$ on valimi elemendid ja $n$ on valimi maht. 

\begin{tabular}{ll}
MS Exceli funktsioon & =AVERAGE(vahemik)\\
R funktsioon & mean(vahemik) \\
\end{tabular}



### Dispersioon

Dispersioon on hälvete ruutude aritmeetiline keskmine. Dispersioon mõõdab andmete hajuvust keskmise ümber. Valimi dispersiooni tähistatakse $s_x^2$. Dispersioon on alati positiivne suurus. Valimi dispersioon arvutatakse järgmise valemi abil:

\[s_x^2 = \frac{1}{n-1} \sum_{i=1}^{n} (x_i - \bar{x})^2\]

kus $x_i$ on valimi elemendid, $\bar{x}$ on valimi aritmeetiline keskmine ja $n$ on valimi maht. Valemist on näha, et valimi dispersiooni arvutamisel kasutatakse jagajat $n-1$. Jagajat $n-1$ kasutatakse, et saada nihketa hinnang üldkogumi dispersioonile, sest kui kasutada jagajat $n$, saadaksime nihkega hinnangu. Suure valimi korral ($n > 100$) on erinevus tühine, aga väikeste valimite korral erinevad need oluliselt. 

\begin{tabular}{ll}
MS Exceli funktsioon & =VAR(vahemik)\\
R funktsioon & var(vahemik) \\
\end{tabular}



### Standardhälve

Standardhälve on ruutjuur dispersioonist. Standardhälve näitab, kui palju andmed keskmisest hajuvad. Valimi standardhälvet tähistatakse $s_e$. Standardhälvet on mugav kasutada, kuna mõõtühik on sama, mis kirjeldataval tunnusel. Standardhälve on alati positiivne. Valimi standardhälve arvutatakse valemiga


\[s_x = \sqrt{s_x^2}\]


kus $s^2$ on valimi dispersioon. 

\begin{tabular}{ll}
MS Exceli funktsioon & =STDEV(vahemik)\\
R funktsioon & sd(vahemik) \\
\end{tabular}


### Standardviga

Standardviga on valimi järgi arvutatud hinnangu standardhälve, mis kirjeldab üldkogumi keskväärtuse või muu parameetri valimist saadud hinnangu täpsust. See näitab, kui palju valimi keskmine võib tegelikust üldkogumi keskmisest erineda. Samast üldkogumist korduvalt võetud valimite keskväärtuste jaotus läheneb normaaljaotusele, mille standardhälve võrdub hinnangu standardveaga. Valimi keskmise standardviga arvutatakse valemiga


\[
s_{\bar{x}} = \frac{s_x}{\sqrt{N}}
\]

kus $s_x$ on valimi standardhälve ja $N$ on valimi maht.

\begin{tabular}{ll}
MS Exceli funktsioon & =STDEV(vahemik)/SQRT(COUNT(vahemik))\\
R funktsioon & sd(vahemik)/sqrt(length(vahemik)) \\
\end{tabular}


### Katsetäpsus

Katsetäpsus on suhteline standardviga protsentides. See näitab standardhälbe osakaalu aritmeetilisest keskmisest. Katsetäpsust arvutatakse järgmiselt:


\[
P_x 
= \frac{s_{\bar{x}}}{\bar{x}} \cdot 100 
= \frac{s_x}{\sqrt{N} \cdot \bar{x}} \cdot 100 
= \frac{V_x}{\sqrt{N}}
\]


kus $V_x$ on variatsioonikordaja.

\begin{tabular}{ll}
MS Exceli funktsioon & =100*STDEV(H)/(AVERAGE(H)\*SQRT(COUNT(H))) \\
R funktsioon & 100*sd(H)/(mean(H)*sqrt(length(H))) \\
\end{tabular}


### Standardhälbe viga

Standardhälbe vea hinnang ehk standardhälbe standardhälve näitab, kui palju võib valimi standardhälve erineda üldkogumi standardhälbest. Standardhälbe viga arvutatakse järgmiselt:


\[s_{s_x} = \frac{s_x}{\sqrt{2 \cdot N}}\]


kus $s_x$ on valimi standardhälve ja $N$ on valimi maht.

\begin{tabular}{ll}
MS Exceli funktsioon & =STDEV(H)/SQRT(2*COUNT(H)) \\
R funktsioon & sd(H)/sqrt(2*length(H)) \\
\end{tabular}


### Dispersiooni viga

Dispersiooni vea hinnang ehk dispersiooni standardhälve arvutatakse valemiga

\[s_{s_x^2} = s_x^2 \cdot \sqrt{\frac{2}{N}}\]

kus $s_x^2$ on valimi dispersioon ja $N$ on valimi maht.

\begin{tabular}{ll}
MS Exceli funktsioon & =VAR(H)*SQRT(2/COUNT(H)) \\
R funktsioon & var(H)*sqrt(2/length(H))
\end{tabular}

### Variatsioonikordaja

Variatsioonikordaja on standardhälbe ja aritmeetilise keskmise suhe. Variatsioonikordaja on ühikuvaba suurus, mis võimaldab võrrelda erinevate ühikutes mõõdetud tunnuste varieeruvust. Variatsioonikordaja arvutatakse valemiga

$$V_x = 100 \cdot \frac{s_x}{\bar{x}}$$
\begin{tabular}{ll}
MS Exceli funktsioon & =100*STDEV(H)/AVERAGE(H)\\
R funktsioon & 100*sd(H)/mean(H) \\
\end{tabular}


### Variatsioonikordaja viga

Variatsioonikordaja vea hinnang ehk variatsioonikordaja standardhälve arvutatakse valemiga

$$s_{V_x} = \frac{V_x}{\sqrt{2 \cdot N}}$$
\begin{tabular}{ll}
MS Exceli funktsioon & =100*STDEV(H)/(SQRT(2*COUNT(H))*AVERAGE(H)) \\
R funktsioon & 100*sd(H)/(sqrt(2*length(H))*mean(H)) \\
\end{tabular}


## Vahemikhinnangud

### Keskväärtuse usalduspiirid

**Keskväärtuse usalduspiirid** on statistilised parameetrid, mis aitavad hinnata valimi põhjal tehtud järelduste täpsust üldkogumi keskväärtuse kohta. Need piirid moodustavad **usaldusvahemiku**, mis näitab, millises vahemikus võib üldkogumi tegelik keskväärtus asuda antud tõenäosusega. Usalduspiirid on seega usaldusvahemiku alumine ja ülemine piir.

Usaldusvahemik **ei ole** vahemik, mis sisaldab valimi väärtusi, vaid see on vahemik, mille sisse me usume tegeliku parameetri (üldkogumi keskväärtuse) langevat teatud tõenäosusega. See vahemik näitab, kui kindlad saame olla, et tegelik parameetri väärtus jääb antud vahemikku. Usaldusvahemikku kasutatakse, kuna valimist arvutatud hinnang on juhuslik suurus, samas kui üldkogumi parameetri tegelik väärtus ei ole juhuslik. Usaldusvahemiku leidmisel lähtutakse valimi keskmisest ja üldkogumi keskväärtus langeb antud usaldatavusega (tõenäosusega) sellesse vahemikku.

Usalduspiiride arvutamiseks kasutatakse valimi andmeid, valitakse teatud **usaldusnivoo** (tavaliselt 95% või 99%) ja arvutatakse vastav usaldusvahemik. Usaldusvahemiku arvutamiseks kasutatakse järgmist valemit:

* Alumine piir:  $\bar{x} - t_{\alpha/2, n-1} \cdot \frac{s_x}{\sqrt{n}}$
* Ülemine piir: $\bar{x} + t_{\alpha/2, n-1} \cdot \frac{s_x}{\sqrt{n}}$

kus:

*   $\bar{x}$ on valimi keskmine
*   $t_{\alpha/2, n-1}$ on t-jaotuse $\alpha/2$ täiendkvantiil vabadusastmete arvuga $n-1$
*   $n$ on vaatluste arv ehk valimi suurus
*   $s_x$ on valimi standardhälve
*   $\alpha$ on olulisusnivoo (1 - usaldusnivoo)

Olulisusnivoo ($\alpha$) määrab tõenäosuse, et tegelik parameetri väärtus **ei jää** usaldusvahemikku. Teisisõnu, see on risk, millega oleme nõus eksima. Tavaliselt kasutatakse olulisusnivood 5% ($\alpha = 0,05$) või 1% ($\alpha = 0,01$). Mida väiksem on olulisusnivoo, seda laiem on usaldusvahemik (oleme kindlamad, et tegelik väärtus sinna jääb). Olulisusnivoo valik sõltub sellest, kumb viga on ohtlikum: kas kehtiva nullhüpoteesi tagasilükkamine (I liiki viga) või mittekehtiva nullhüpoteesi vastuvõtmine (II liiki viga). Praktikas peetakse I liiki vigu tavaliselt ohtlikumaks ja seetõttu eelistatakse madalamat olulisusnivood.

Usaldusvahemik võib olla **ühe-** või **kahepoolne**. **Kahepoolset** usaldusvahemikku kasutatakse siis, kui me soovime hinnata, kas tegelik parameeter võib olla nii suurem kui ka väiksem kui valimi keskmine. **Ühepoolset** usaldusvahemikku kasutatakse siis, kui oleme huvitatud ainult sellest, kas parameeter on suurem või väiksem kui teatud väärtus. Ühepoolse usalduspiiriga piirdumine on põhjendatud, kui hinnangu hälve vastassuunas on välistatud (nt mingi näitaja ei saa olla negatiivne). Kahepoolse testi puhul on $t$-väärtus arvutatud $\alpha/2$ jaoks, ühepoolse testi puhul $\alpha$ jaoks.

Väikese valimi korral ei pruugi eelnevalt toodud valemid olla täpsed, eriti osakaalude hindamisel. Ligikaudsest valemist leitud usaldusvahemiku alumine piir võib tulla negatiivne, mis ei ole reaalne (nt osakaal ei saa olla negatiivne). Sellisel juhul tuleks kasutada täpseid binoomjaotusel põhinevaid valemeid (nt Clopper-Pearsoni meetod). Suuremate valimite korral langevad täpse ja ligikaudse valemi tulemused kokku.

Keskväärtuse usalduspiiride leidmine ja hüpoteeside testimine on omavahel tihedalt seotud. Kui meil on nullhüpotees $H_0: \mu = \mu_0$, siis kui valimi keskmine $\bar{x}$ langeb piirkonda, kus olulisusnivool $\alpha$ võetakse vastu $H_0$, siis $\mu_0$ asub valimi põhjal usaldatavusega $\beta = 1-\alpha$ leitud keskväärtuse usaldusvahemikus. Hüpoteesi testimisel lähtume nullhüpoteesiga püstitatud väärtusest $\mu_0$, aktsepteerimisvahemik on sellest mõlemale poole, ja me aktsepteerime nullhüpoteesi, kui valimi keskmine $\bar{x}$ jääb sellesse vahemikku. Keskväärtuse usaldusvahemiku leidmisel lähtume aga valimi keskmisest $\bar{x}$ ja üldkogumi keskväärtus $\mu$ langeb antud usaldatavusega sellesse vahemikku.

\begin{naidis}
Vaatleme näites 1.4 esitatud valimit, milles on antud sambliku kasvukohatüübis kasvava 50-aastase männiku 60 juhuslikult valitud puu kõrguste andmed. Arvutame kõrguse keskväärtuse 95%-lised usalduspiirid.
\end{naidis}

Näites on  selle valimi andmete põhjal arvutatud 
\begin{tabular}{lr}
kõrguse aritmeetiline keskmine & 12,082 m \\
ja kõrguse standardhälve & 1,185 m \\
\end{tabular}

**MS Excel keskkonnas **

$\mu_{0,025}$ = - TINV(0,05 ; N-1) * sh /SQRT(N) = 12,082 - 2,001·1,185/  = 11,78 m;

$\mu_{0,975}$ = + TINV(0,05 ; N-1) * sh /SQRT(N)  = 12,082 + 2,001·1,185/  = 12,39 m.

**R keskkonnas**

```{r, warning=F, message=F}
korgus <- as.vector(unlist(readxl::read_excel("data/naited.xlsx","N14", col_names = F)))
korgus <- korgus[!is.na(korgus)]
N = length(korgus)
H = mean(korgus)
se = sd(korgus)
H + qt(0.025,df=N-1) * se / sqrt(N)
H + qt(0.975,df=N-1) * se / sqrt(N)

# Kordame sama funktsiooniga t.test
t.test(korgus)

```

### Dispersiooni usalduspiirid

Dispersiooni usalduspiirid on statistiline tööriist, mis võimaldab hinnata, kui täpselt iseloomustab valimi dispersioon üldkogumi dispersiooni. Dispersioon kirjeldab andmete hajuvust keskväärtuse ümber ning usalduspiirid annavad meile vahemiku, milles teatud kindlusega (usaldusnivooga) asub tegeliku üldkogumi dispersiooni väärtus.

Dispersioon on statistiline mõõdik, mis näitab andmepunktide hajuvust keskmise ümber. Üldkogumi dispersiooni tähistatakse tavaliselt $\sigma^2$ ja valimi dispersiooni $s^2$. Valimi dispersioon on üldkogumi dispersiooni punkthinnang, kuid paratamatult esineb erinevus tegeliku väärtusega. Seega on dispersiooni usalduspiiride kasutamine oluline, et saada parem ülevaade tegeliku dispersiooni väärtusest.

Usaldusvahemik on väärtuste vahemik, mis teatud tõenäosusega sisaldab otsitava üldkogumi parameetri (antud juhul dispersiooni) tegelikku väärtust. Usalduspiirid on selle vahemiku alumine ja ülemine piir. Need piirid defineerivad ala, kuhu üldkogumi dispersioon langeb etteantud tõenäosusega (usaldusnivooga).

Dispersiooni usalduspiiride arvutamine on keerukam kui keskväärtuse usalduspiiride arvutamine. Tavaliselt kasutatakse selleks $\chi^2$-jaotust (hii-ruut-jaotust). $\chi^2$-jaotus on asümmeetriline jaotus, mille kuju sõltub vabadusastmete arvust. Valimi dispersiooni usalduspiirid $(1-\alpha)$ usaldusnivoo jaoks arvutatakse järgmiselt:

*   Alumine piir: $\frac{(n-1)s^2}{\chi^2_{\alpha/2, n-1}}$
*   Ülemine piir: $\frac{(n-1)s^2}{\chi^2_{1-\alpha/2, n-1}}$

kus:

*   $n$ on valimi suurus
*   $s^2$ on valimi dispersioon
*   $\chi^2_{\alpha/2, n-1}$ on $\chi^2$-jaotuse $\alpha/2$ kvantiil vabadusastmete arvuga $n-1$
*   $\chi^2_{1-\alpha/2, n-1}$ on $\chi^2$-jaotuse $1-\alpha/2$ kvantiil vabadusastmete arvuga $n-1$
*   $\alpha$ on olulisusnivoo (ehk eksimisvõimalus)

**Standardhälbe usalduspiiride** saamiseks võetakse ruutjuur dispersiooni usalduspiiridest.

\begin{naidis}
Vaatleme näites 1.4 esitatud valimit, milles on antud sambliku kasvukohatüübis kasvava 50-aastase männiku 60 juhuslikult valitud puu kõrguste andmed. Arvutame kõrguse dispersiooni 95%-lised usalduspiirid.
\end{naidis}

Näites on  selle valimi andmete põhjal arvutatud 
\begin{tabular}{lr}
kõrguse aritmeetiline keskmine & 12,082 m \\
kõrguse dispersioon & 1,405 m \\
\end{tabular}

MS Exceli keskkonnas: 

$$\sigma_{0,025}^2 = (N-1)*s_x^2/CHIINV(\alpha/2; N-1) = (60 - 1)*1,4046/82,12 = 1,01;$$
$$\sigma_{0,975}^2 = (N-1)*s_x^2/CHIINV(1-\alpha ; N-1) = (60 - 1)*1,4046/39,66 = 2,09.$$

R keskkonnas: 

```{r}
N = length(korgus)
H = mean(korgus)
se2 = var(korgus)

(vra = (N-1)*se2/qchisq(0.975,N-1))
(vry = (N-1)*se2/qchisq(0.025,N-1))
```

Saadud tulemuste põhjal võib väita, et valimi dispersioon on `r round(se2,3)` ning 95% tõenäosusega on dispersioon
vahemikus `r round(vra,3)` m kuni `r round(vry,3)` m Standardhälbe usalduspiiride saamiseks tuleb võtta saadud väärtustest ruutjuur – `r round(sqrt(vra),3)` m kuni `r round(sqrt(vry),3)` m.

### Standardhälbe usalduspiirid

Standardhälbe usalduspiirid on statistilised vahendid, mis aitavad hinnata üldkogumi standardhälbe $\sigma$ määramise täpsust valimi standardhälbe $s$ põhjal. Need piirid moodustavad usaldusvahemiku, mis näitab, millises vahemikus asub üldkogumi tegelik standardhälve $\sigma$ antud usaldusnivooga (tõenäosusega). Standardhälve iseloomustab andmete hajuvust keskväärtuse ümber ja usalduspiirid on usaldusvahemiku alumine ja ülemine piir.

Standardhälbe usalduspiire arvutatakse sarnaselt dispersiooni usalduspiiride arvutamisega, kasutades $\chi^2$-jaotust (hii-ruut-jaotust). $\chi^2$-jaotus on asümmeetriline jaotus, mille kuju sõltub vabadusastmete arvust. Standardhälbe usalduspiirid $1-\alpha$ usaldusnivoo korral arvutatakse järgmiselt:

*   Alumine piir: $L = \sqrt{\frac{(n-1)s^2}{\chi^2_{\alpha/2, n-1}}}$
*   Ülemine piir: $U = \sqrt{\frac{(n-1)s^2}{\chi^2_{1-\alpha/2, n-1}}}$

kus:

*   $n$ on valimi suurus
*   $s^2$ on valimi dispersioon (valimi standardhälbe ruut)
*   $\chi^2_{\alpha/2, n-1}$ on $\chi^2$-jaotuse $\alpha/2$ kvantiil vabadusastmete arvuga $n-1$
*   $\chi^2_{1-\alpha/2, n-1}$ on $\chi^2$-jaotuse $1-\alpha/2$ kvantiil vabadusastmete arvuga $n-1$
*   $\alpha$ on olulisusnivoo (eksimise tõenäosus)


### Binoomjaotuse parameetri p usalduspiirid

Binoomjaotuse parameetri *p* usalduspiirid annavad vahemiku, milles tõenäoliselt asub sündmuse tegelik toimumise tõenäosus *p*, arvestades binoomjaotusega kirjeldatud katsete seeriat. Binoomjaotus on diskreetne tõenäosusjaotus, mis kirjeldab sõltumatute katsete seerias õnnestumiste arvu, kus igal katsel on kaks võimalikku tulemust: õnnestumine või ebaõnnestumine. Parameeter *p* tähistab õnnestumise tõenäosust ühes katses.

Binoomjaotus on määratud kahe parameetriga: *n* (katsete arv) ja *p* (õnnestumise tõenäosus ühes katses). Binoomjaotust tähistatakse sageli B(*n*, *p*). Kui sooritame *n* sõltumatut katset ja iga katse õnnestumise tõenäosus on *p*, siis binoomjaotusega juhusliku suuruse X (õnnestumiste arv) tõenäosus on antud valemiga:

$$p_{\alpha/2} = \frac{k}{k + (n-k + 1) \cdot F_{\alpha/2,2 \cdot (n-k+1), 2\cdot k}}$$
$$p_{1- \alpha/2} = \frac{k+1}{(k+1)+(n-k) / F_{\alpha/2,2\cdot (k+1), 2 \cdot (n-k)}}$$
\begin{naidis}
Seemnepartii idanevustõenäosuse teadasaamiseks idandati partiist 70 juhuslikult valitud seemet, millest idanes 19. Leida seemnete idanevustõenäosuse usalduspiirid, võttes usaldusnivooks 0,95.
\end{naidis}

Seemnepartii idanevustõenäosuse 95%-lised usalduspiirid avalduvad MS Excelis all-järgnevate valemitega: 

$p_{0,025}$ = k/(k+(n-k+1)*FINV(0,025;2*(n-k+1);2*k)) = 19/(19+52·1,759) = 0,172;

$p_{0,975}$ = (k+1)/((n-k)/FINV(0,025;2*(k+1);2*(n-k))+k+1) = 20/(51/1,637+20) = 0,391.

R keskkonnas saab seda arvutada funktsiooniga `binom.test()`
```{r}
binom.test(19, 70, 19/70)
```

## Valimi mahu hindamine

Üldkogumi parameetrite veahinnangud sõltuvad valimi mahust. Üldiselt tuleb hinnangu täpsuse suurendamiseks k korda suurendada valimi mahtu 2 * k korda. Praktilises metsanduslikus uurimistöös tekib tihti küsimus, kui palju tuleks mõõta puid, rajada proovitükke jne, et saadud tulemused iseloomustaksid üldkogumit piisava täpsusega. 

\begin{naidis}
Vaatleme näites 1.4 esitatud valimit, milles on antud sambliku kasvukohatüübis kasvava 50-aastase männiku 60 juhuslikult valitud puu kõrguste andmed. 
\end{naidis}

Näites on  selle valimi andmete põhjal arvutatud 
\begin{tabular}{lr}
kõrguse aritmeetiline keskmine & 12,082 m \\
kõrguse standardhälve & 1,185 m \\
kõrguse variatsioonikordaja  & 9,81\% \\
\end{tabular}

Arvutame järgmise hinnangud:

* Puistu kõrguse keskväärtuse saamiseks katsetäpsusega $\delta$ = 1% tuleks mõõta
  * N = $(Vh/\delta)^2$ = $(9,81/1)^2$ $\approx$ 96 puud.
* Puistu kõrguse keskväärtuse saamiseks standardveaga  $\epsilon$ = 0,1 m tuleks mõõta
  * N = $(sh/\epsilon)^2$ = $(1,185/0,1)^2$ $\approx$ 140 puud.
* Puistu kõrguse keskväärtust veaga alla 0,1 m tuleks mõõta
  * N = $(NORMSINV(0,975)*sh/\epsilon)^2$ = $(1,96 * 1,185/0,1)^2$ $\approx$ 539 puud.

## Statistilised hüpoteesid

### F-test normaaljaotusega üldkogumite dispersioonide võrdlemiseks

F-test on statistiline test, mida kasutatakse kahe või enama normaaljaotusega üldkogumi dispersioonide võrdlemiseks. See test võimaldab hinnata, kas kahe valimi varieeruvus on oluliselt erinev, mis on oluline eeldus mitmete teiste statistiliste testide, näiteks t-testi, kasutamisel. F-testi kasutatakse nii kahepoolsete kui ka ühepoolsete hüpoteeside kontrollimiseks.

F-testi rakendamisel on oluline seada hüpoteesid, mida soovitakse testida.  Hüpoteesid sõltuvad sellest, kas soovitakse testida dispersioonide erinevust üldiselt (kahepoolne test) või uurida, kas ühe kogumi dispersioon on suurem kui teise (ühepoolne test).

*   **Kahepoolne hüpotees.**
    *   Nullhüpotees ($H_0$): dispersioonid on võrdsed, st  $\sigma_1^2 = \sigma_2^2$.
    *   Alternatiivne hüpotees ($H_1$): dispersioonid on erinevad, st $\sigma_1^2 \neq \sigma_2^2$.
*   **Ühepoolne hüpotees.**
    *   Nullhüpotees ($H_0$): ühe kogumi dispersioon on väiksem või võrdne teise kogumi dispersiooniga, st $\sigma_1^2 \leq \sigma_2^2$ või $\sigma_1^2 \geq \sigma_2^2$.
    *   Alternatiivne hüpotees ($H_1$): ühe kogumi dispersioon on suurem kui teise kogumi dispersioon, st $\sigma_1^2 > \sigma_2^2$ või $\sigma_1^2 < \sigma_2^2$.

**Teststatistiku arvutamine**

F-statistiku arvutamiseks jagatakse suurema valimi dispersioon väiksemaga:

$F = \frac{s_1^2}{s_2^2}$

kus $s_1^2$ ja $s_2^2$ on valimite dispersioonid.  On oluline, et lugejas oleks suurema dispersiooniga valim (seega alati $F \geq 1$). F-statistik allub F-jaotusele vabadusastmete arvudega $n_1 - 1$ ja $n_2 - 1$, kus $n_1$ ja $n_2$ on vastavate valimite mahud. F-jaotus on asümmeetriline ja selle kuju sõltub vabadusastmetest.

**Otsustamine ja kriitilised väärtused**

F-testi tulemuste tõlgendamiseks võrreldakse arvutatud F-statistiku väärtust kriitiliste väärtustega, mis saadakse F-jaotusest vastava olulisuse nivoo ($\alpha$) ja vabadusastmete alusel. Olulisuse nivoo on tavaliselt seatud 0,05-le, mis tähendab, et on 5% tõenäosus teha I tüübi viga ehk lükata tagasi õige nullhüpotees.

*   **Kahepoolse hüpoteesi korral** on kaks kriitilist väärtust, $F_{krv}$ ja $F_{krp}$, mis asuvad vastavalt F-jaotuse vasakul ja paremal pool.  Nullhüpotees lükatakse tagasi, kui $F < F_{krv}$ või $F > F_{krp}$.
    *   Vasakpoolne kriitiline väärtus: $F_{krv} = F^{-1}_{\alpha/2}(n_2 - 1, n_1 - 1)$.
    *   Parempoolne kriitiline väärtus: $F_{krp} = F_{\alpha/2}(n_1 - 1, n_2 - 1)$.
*   **Ühepoolse hüpoteesi korral** (eeldades, et testime $H_1: \sigma_1^2 > \sigma_2^2$) on üks kriitiline väärtus, mis asub F-jaotuse paremal poolel. Nullhüpotees lükatakse tagasi, kui $F > F_{kr}$.  Kui testime $H_1: \sigma_1^2 < \sigma_2^2$, siis asub kriitiline väärtus vasakul pool ja nullhüpotees lükatakse tagasi, kui $F<F_{kr}$.
    * Parempoolne kriitiline väärtus (kui $\sigma_1^2 > \sigma_2^2$): $F_{kr} = F_{\alpha}(n_1 - 1, n_2 - 1)$.
    * Vasakpoolne kriitiline väärtus (kui $\sigma_1^2 < \sigma_2^2$): $F_{kr} = F^{-1}_{\alpha}(n_2 - 1, n_1 - 1)$.

\begin{naidis}
Olgu uurimisobjektiks suhteliselt homogeensel alal sambliku kasvu¬koha¬tüübi 24-aastased männikultuurid, millest osa on rajatud põlenud ja osa põlemata pinna¬sele. Põlenud alale rajati 8 ja põlemata alale 5 proovitükki. Proovitükkide andmete töötlemise tulemusel saadi järgmised puistute kõrgused meetrites.

Põlenud alal: 4,3; 3,4; 3,9; 2,9; 4,9; 3,2; 3,7; 3,6.

Põlemata alal: 4,8; 4,3; 5,4; 5,1; 4,6.
\end{naidis}

Meid huvitab, kas põlenud ja põlemata alal on puistute kõrguse dispersioonid erinevad.

MS Exceli funktsiooniga 
=FTEST(andmeplokk1 ; andmeplokk2)
Antud näite korral on dispersioonide erinevuse olulisuse tõenäosus p = 0,47.


R keskkonnas saab selleks kasutada funktsiooni `var.test()`.
```{r}
polenud <- c(4.3, 3.4, 3.9, 2.9, 4.9, 3.2, 3.7, 3.6)
polemata <- c(4.8, 4.3, 5.4, 5.1, 4.6)
var.test(polenud,polemata)
```

### Keskmiste võrdlemine paarikaupa andmete korral normaaljaotusega üldkogumist

Paarikaupa andmete korral keskmiste võrdlemine normaaljaotusega üldkogumistest (sõltuvate valimite t-test) võimaldab hinnata, kas mingi toiming (nt protseduur, sekkumine) on põhjustanud statistiliselt olulise muutuse üldkogumi keskväärtuses.  Seda tehakse, võrreldes sama objekti kahte mõõtmist (nt enne ja pärast toimingut).

**Hüpoteesid**

Paarikaupa andmete korral sõnastatakse hüpoteesid järgmiselt:

*   **Nullhüpotees ($H_0$).** Toiming ei mõjutanud üldkogumi keskväärtust, st keskväärtuste vahe on null.
    $H_0: \mu_1 = \mu_2$  või  $H_0: \mu_d = 0$, kus $\mu_d$ on populatsiooni keskmine erinevus.

*   **Alternatiivne hüpotees ($H_1$ või $H_a$).** Toiming mõjutas üldkogumi keskväärtust.  Alternatiivne hüpotees võib olla:
    *   **Kahepoolne.** Keskväärtus muutus (suund määramata).
        $H_1: \mu_1 \neq \mu_2$  või  $H_1: \mu_d \neq 0$
    *   **Ühepoolne.**
        *   Keskväärtus suurenes: $H_1: \mu_1 < \mu_2$ või $H_1: \mu_d > 0$ (vaadates *enne - pärast* erinevust, on oodatav erinevus positiivne)
        *   Keskväärtus vähenes: $H_1: \mu_1 > \mu_2$ või $H_1: \mu_d < 0$ (vaadates *enne - pärast* erinevust, on oodatav erinevus negatiivne)

**Teststatistik**

Paarikaupa andmete korral arvutatakse t-statistik, kasutades iga paari mõõtmiste vahesid ($d_i$).

1.  **Vahede arvutamine.**  $d_i = x_{1i} - x_{2i}$, kus $x_{1i}$ on *i*-nda objekti esimene mõõtmine ja $x_{2i}$ on *i*-nda objekti teine mõõtmine.

2.  **Vahede keskmise arvutamine.** $\bar{d} = \frac{\sum_{i=1}^{n} d_i}{n}$, kus $n$ on paaride arv.

3.  **Vahede standardhälbe arvutamine.** $s_d = \sqrt{\frac{\sum_{i=1}^{n} (d_i - \bar{d})^2}{n-1}}$

4.  **t-statistiku arvutamine.**
    $$t = \frac{\bar{d}}{s_d / \sqrt{n}}$$

t-statistik järgib t-jaotust $n-1$ vabadusastmega.  t-jaotus on sümmeetriline, sarnaneb normaaljaotusega, kuid on väiksemate valimite korral laiema "sabaga".

**Otsuse tegemine**

Otsus nullhüpoteesi kohta tehakse, võrreldes arvutatud t-statistikut kriitilise väärtusega ($t_{kr}$) või hinnates p-väärtust.

*   **Kriitiline väärtus ($t_{kr}$).**  See leitakse t-jaotuse tabelist või statistikatarkvara abil, lähtudes valitud olulisuse nivost ($\alpha$, tavaliselt 0.05) ja vabadusastmete arvust ($n-1$). Olulisuse nivoo $\alpha$ tähistab I tüübi vea (valesti tagasilükatud tõese nullhüpoteesi) tõenäosust.
    *   **Kahepoolse testi korral.**  Nullhüpotees lükatakse tagasi, kui $|t| > t_{kr}$, st $t < -t_{kr}$ või $t > t_{kr}$.  Kriitiline väärtus $t_{kr}$ vastab $\alpha/2$ kummalgi jaotuse sabal.
    *   **Ühepoolse testi korral.**
        *   Kui $H_1: \mu_d > 0$:  Nullhüpotees lükatakse tagasi, kui $t > t_{kr}$.
        *   Kui $H_1: \mu_d < 0$:  Nullhüpotees lükatakse tagasi, kui $t < -t_{kr}$.

*   **p-väärtus.**  See on tõenäosus saada vähemalt sama äärmuslik (või veel äärmuslikum) t-statistik, kui nullhüpotees on tõene.
    *   Nullhüpotees lükatakse tagasi, kui p-väärtus $\leq \alpha$.

**Eeldused**

Sõltuvate valimite t-testi eeldused on:

1.  **Normaaljaotus.** Mõõtmiste *vahed* ($d_i$) peaksid olema ligikaudu normaaljaotusega.  See eeldus on vähem oluline suuremate valimite korral (tänu tsentraalsele piirteoreemile).
2.  **Sõltumatus.** Vaatlused (mõõtmispaarid) peavad olema üksteisest sõltumatud.
3. **Mõõtmiste skaala.** Mõõtmised on intervallskaalal või suhtarvulisel skaalal.



### Sõltumatuse hii-ruut-test

Sõltumatuse hii-ruut-test ( $\chi^2$-test) on statistiline meetod, mida kasutatakse kahe kvalitatiivse tunnuse vahelise seose uurimiseks.  Test hindab, kas kahe tunnuse jaotused on omavahel seotud või sõltumatud. Testi eesmärk on kummutada nullhüpotees ($H_0$), mis väidab, et tunnuste vahel seost ei ole.

**Põhimõtted ja rakendused**

$\chi^2$-testi kasutatakse sagedusandmete analüüsimiseks, mis on esitatud risttabelina (kontingentsitabelina).  Risttabeli read esitavad ühe tunnuse väärtusi ja veerud teise tunnuse väärtusi. Test võimaldab uurida, kas ühe tunnuse jaotus sõltub teise tunnuse väärtustest. Näiteks saab testida, kas vastused küsimustele sõltuvad vastaja soost või vanusest. $\chi^2$-testi kasutatakse ka empiirilise ja teoreetilise jaotuse võrdlemiseks, et teha kindlaks, kas juhuslik suurus allub valitud jaotusseadusele.

**Hüpoteesid**

Sõltumatuse $\chi^2$-testi hüpoteesid on:

*   **Nullhüpotees ($H_0$).** Tunnuste vahel seost ei ole (tunnused on sõltumatud). Ühe tunnuse jaotus ei sõltu teise tunnuse väärtustest.
*   **Alternatiivne hüpotees ($H_1$).** Tunnuste vahel on seos (tunnused ei ole sõltumatud). Ühe tunnuse jaotus sõltub teise tunnuse väärtustest.

**Teststatistiku arvutamine**

$\chi^2$-teststatistiku arvutamise valem:

$$
\chi^2 = \sum_{i=1}^{r} \sum_{j=1}^{k} \frac{(O_{ij} - E_{ij})^2}{E_{ij}}
$$

kus:

*   $O_{ij}$ on vaadeldud (empiiriline) sagedus risttabeli lahtris *i, j*.
*   $E_{ij}$ on oodatav sagedus risttabeli lahtris *i, j*, kui tunnused oleksid sõltumatud.
*   $r$ on ridade arv risttabelis.
*   $k$ on veergude arv risttabelis.

Oodatava sageduse arvutamise valem:

$$
E_{ij} = \frac{(\text{rea } i \text{ summa}) \times (\text{veeru } j \text{ summa})}{\text{üldsumma}} = \frac{(\sum_{j=1}^{k} O_{ij}) \times (\sum_{i=1}^{r} O_{ij})}{\sum_{i=1}^{r} \sum_{j=1}^{k} O_{ij}}
$$

**Vabadusastmed**

Vabadusastmete arv ($\nu$) leitakse valemiga:


$$\nu = (r - 1) \times (k - 1)$$


**Otsuse tegemine**

Otsuse tegemiseks võrreldakse arvutatud $\chi^2$ väärtust kriitilise väärtusega ($\chi^2_{\alpha, \nu}$), mis saadakse $\chi^2$-jaotusest vastava vabadusastmete arvu ($\nu$) ja valitud olulisuse nivoo ($\alpha$) alusel (tavaliselt $\alpha = 0.05$).

*   Kui $\chi^2 > \chi^2_{\alpha, \nu}$ või p-väärtus $< \alpha$, siis lükatakse nullhüpotees tagasi ja järeldatakse, et tunnuste vahel on statistiliselt oluline seos.
*   Kui $\chi^2 \leq \chi^2_{\alpha, \nu}$ või p-väärtus $\geq \alpha$, siis jäädakse nullhüpoteesi juurde (ei saa tõestada, et tunnuste vahel on seos).


**Eeldused**

$\chi^2$-testi kasutamisel on oluline arvestada järgmisi eeldusi:

*   **Sõltumatud vaatlused.** Vaatlused peavad olema üksteisest sõltumatud.
*   **Piisavalt suured oodatavad sagedused.** Üldjuhul peaksid kõik oodatavad sagedused ($E_{ij}$) olema vähemalt 5. Mõned allikad lubavad ka väiksemaid väärtusi, kuid kui rohkem kui 20% oodatavatest sagedustest on alla 5, või on mõni oodatav sagedus alla 1, võib test olla ebausaldusväärne. Sellisel juhul võib kasutada Yates'i korrektsiooni või Fisheri täpset testi.

